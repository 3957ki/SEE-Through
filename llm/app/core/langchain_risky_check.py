import json
from langchain_openai import ChatOpenAI
from langchain.output_parsers import PydanticOutputParser, OutputFixingParser
from langchain.prompts import ChatPromptTemplate
from pydantic import BaseModel, Field
from sqlalchemy.orm import Session
from app.db.models import DiseaseVector
from app.core.embedding import get_embeddings
import logging

logger = logging.getLogger(__name__)

from app.core.config import OPENAI_API_KEY

### ìœ„í—˜ ìŒì‹ ì½”ë©˜íŠ¸ ìƒì„±
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.7, openai_api_key=OPENAI_API_KEY)


# JSON ì‘ë‹µì„ ê°•ì œí•  ìŠ¤í‚¤ë§ˆ ì •ì˜
class RiskyFoodSchema(BaseModel):
    food_name: str = Field(..., description="ìŒì‹ ì´ë¦„")
    comment: str = Field(..., description="ì‚¬ìš©ìì—ê²Œ ì œê³µí•  ê²½ê³  ë©”ì‹œì§€")


class RiskyFoodList(BaseModel):
    foods: list[RiskyFoodSchema]


# LangChain OutputParser ì ìš© (LLMì˜ ì‘ë‹µì„ JSONìœ¼ë¡œ ê°•ì œ)
parser = PydanticOutputParser(pydantic_object=RiskyFoodList)

fixing_parser = OutputFixingParser.from_llm(parser=parser, llm=llm)

# LLM í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜ (JSON ì¶œë ¥ ê°•ì œ)
prompt_risky = ChatPromptTemplate.from_template(
    """
ë‹¹ì‹ ì€ ì˜ë£Œ ë° ì‹í’ˆ ì•ˆì „ ì „ë¬¸ê°€ ì—­í• ì„ ìˆ˜í–‰í•˜ëŠ” AIì…ë‹ˆë‹¤.

ì•„ë˜ì˜ ìŒì‹ ëª©ë¡ì„ ë¶„ì„í•˜ì—¬ **ì‚¬ìš©ìì˜ ì•Œë ˆë¥´ê¸° ì •ë³´ ë° ì§ˆë³‘ ì •ë³´ì— ë”°ë¼ ì„­ì·¨ ì‹œ ìœ„í—˜í•  ìˆ˜ ìˆëŠ” ìŒì‹**ì— ëŒ€í•´  
**ì˜í•™ì ìœ¼ë¡œ êµ¬ì²´ì ì¸ ì´ìœ ì™€ í•¨ê»˜ ê²½ê³  ë©”ì‹œì§€ë¥¼ ì‘ì„±í•˜ì„¸ìš”.**

ğŸ’¡ ë°˜ë“œì‹œ ë‹¤ìŒ ì›ì¹™ì„ ì§€í‚¤ì„¸ìš”:

1. **ì‚¬ìš©ìì˜ ì•Œë ˆë¥´ê¸° ëª©ë¡ì— í¬í•¨ëœ ìŒì‹**ì€, ì•Œë ˆë¥´ê¸° ë°˜ì‘ì˜ êµ¬ì²´ì ì¸ ì¦ìƒì´ë‚˜ ê¸°ì „(ì˜ˆ: íˆìŠ¤íƒ€ë¯¼ ë¶„ë¹„, ì•„ë‚˜í•„ë½ì‹œìŠ¤ ë“±)ì„ ì–¸ê¸‰í•˜ë©° ì„¤ëª…í•©ë‹ˆë‹¤.
2. **ì‚¬ìš©ìì˜ ì§ˆë³‘ ì •ë³´ì— ë”°ë¼ ì£¼ì˜í•´ì•¼ í•  ìŒì‹**ì€, í•´ë‹¹ ìŒì‹ì´ í•´ë‹¹ ì§ˆë³‘ì— ì–´ë–¤ ì˜í–¥ì„ ì£¼ëŠ”ì§€ êµ¬ì²´ì ìœ¼ë¡œ ì„œìˆ í•©ë‹ˆë‹¤.
   - ì˜ˆ: ë‹¹ë‡¨ â†’ ê³ ë‹¹ë¶„ ìŒì‹ì€ í˜ˆë‹¹ì„ ê¸‰ê²©íˆ ìƒìŠ¹ì‹œì¼œ ìœ„í—˜
   - ê³ í˜ˆì•• â†’ ë‚˜íŠ¸ë¥¨ ê³¼ë‹¤ë¡œ í˜ˆì•• ìƒìŠ¹ ìœ„í—˜
   - ì‹ ì¥ì§ˆí™˜ â†’ ì¹¼ë¥¨/ì¸ í•¨ëŸ‰ì´ ë†’ì€ ìŒì‹ì€ ì‹ ì¥ ë¶€ë‹´ ì¦ê°€
3. **ì „ë¬¸ì ì´ê³  ë‹¤ì–‘í•˜ê²Œ í‘œí˜„í•˜ë©°, ì ˆëŒ€ ë‹¨ìˆœ ë¬¸ì¥ ë°˜ë³µ ê¸ˆì§€**
4. ì‚¬ìš©ìì˜ ì…ë ¥ì— ì—†ëŠ” ì•Œë ˆë¥´ê¸°/ì§ˆë³‘ ì •ë³´ëŠ” ì ˆëŒ€ ê¸°ë°˜ìœ¼ë¡œ ì‚¼ì§€ ë§ˆì„¸ìš”
5. ë©”ì‹œì§€ëŠ” ë°˜ë“œì‹œ ì‹¤ì œ ìœ„í—˜ì„±ì„ ê¸°ë°˜ìœ¼ë¡œ í•˜ë˜, ê³¼ë„í•˜ê²Œ ë¶ˆì•ˆì„ ì¡°ì¥í•˜ì§€ ì•Šë„ë¡ ì£¼ì˜í•˜ì„¸ìš”.

---

ğŸ½ï¸ ìŒì‹ ëª©ë¡:
{food_names}

ğŸ§¬ ì‚¬ìš©ìì˜ ì•Œë ˆë¥´ê¸° ëª©ë¡:
{allergies_name}

ğŸ©º ì‚¬ìš©ìì˜ ì§ˆë³‘ ëª©ë¡:
{disease_name}

ğŸ“š ì°¸ê³ í•  ìˆ˜ ìˆëŠ” ì˜ë£Œ ì •ë³´:
{medical_info}

---

ğŸ“„ ì•„ë˜ JSON ìŠ¤í‚¤ë§ˆ í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:
{format_instructions}

- ìŒì‹ì´ ìœ„í—˜í•˜ì§€ ì•Šìœ¼ë©´ í•´ë‹¹ í•­ëª©ì€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
- ì—¬ëŸ¬ ìŒì‹ì´ ìœ„í—˜í•œ ê²½ìš°, ëª¨ë‘ í¬í•¨ëœ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ì¶œë ¥í•˜ì„¸ìš”.
"""
)


# ë²¡í„° ê¸°ë°˜ ìœ ì‚¬ ì§ˆë³‘ ì •ë³´ ê²€ìƒ‰
def retrieve_medical_info_by_batch_vector(
    food_names: list[str], user_diseases: list[str], db: Session, top_k: int = 3
) -> str:
    try:
        # 1. ìŒì‹ ì´ë¦„ ë°°ì¹˜ ì„ë² ë”©
        embeddings = get_embeddings(food_names)

        # 2. ì§ˆë³‘ í•„í„°ë§ëœ ëª¨ë“  ë²¡í„° ê°€ì ¸ì˜¤ê¸°
        candidate_vectors = (
            db.query(DiseaseVector)
            .filter(DiseaseVector.disease.in_(user_diseases))
            .all()
        )

        # 3. ìœ ì‚¬ë„ ê³„ì‚° (local)
        import numpy as np
        from numpy.linalg import norm

        medical_infos = []
        for idx, food_name in enumerate(food_names):
            food_vec = np.array(embeddings[idx])
            scored = []

            for candidate in candidate_vectors:
                candidate_vec = np.array(candidate.embedding)
                similarity = np.dot(food_vec, candidate_vec) / (
                    norm(food_vec) * norm(candidate_vec)
                )
                scored.append((similarity, candidate))

            # ìœ ì‚¬í•œ top_kë§Œ ì¶”ì¶œ
            top_related = sorted(scored, key=lambda x: -x[0])[:top_k]
            # ì¤‘ë³µ ì œê±°ë¥¼ ìœ„í•œ set ì‚¬ìš©
            medical_infos_set = set()

            for _, vec in top_related:
                info_line = f"ğŸ“Œ '{vec.ingredient}'ì€(ëŠ”) '{vec.disease}' í™˜ìì—ê²Œ ì£¼ì˜ê°€ í•„ìš”í•©ë‹ˆë‹¤: {vec.reason}"
                medical_infos_set.add(info_line)

            # ìµœì¢… ë¬¸ìì—´ë¡œ ê²°í•©
            return "\n".join(sorted(medical_infos_set)) if medical_infos_set else "ì—†ìŒ"

    except Exception as e:
        print(f"[ë²¡í„° ê²€ìƒ‰ ì˜¤ë¥˜] ì—ëŸ¬: {e}")
        return "ì—†ìŒ"


# LLM ë¶„ì„ í•¨ìˆ˜ (ë²¡í„° ê¸°ë°˜ context í¬í•¨)
def analyze_risky_foods_with_comments(
    food_names: list, allergies: list, diseases: list, db: Session
) -> list:
    """
    LLMì„ ì´ìš©í•˜ì—¬ ìŒì‹ì˜ ìœ„í—˜ì„±ì„ ë¶„ì„í•˜ê³ , í•„ìš”í•œ ê²½ìš° ê²½ê³  ë©”ì‹œì§€ë¥¼ ì œê³µí•˜ëŠ” í•¨ìˆ˜
    """

    food_list_str = "\n".join([f"- {food}" for food in food_names])
    allergy_list_str = "\n".join([f"- {allergy}" for allergy in allergies])
    disease_list_str = "\n".join([f"- {disease}" for disease in diseases])

    # ë²¡í„° ê¸°ë°˜ ìœ ì‚¬ ì˜ë£Œ ì •ë³´ ê²€ìƒ‰
    medical_info_str = retrieve_medical_info_by_batch_vector(food_names, diseases, db)
    logger.info("ğŸ“š LLM í”„ë¡¬í”„íŠ¸ì— í¬í•¨ëœ ì˜ë£Œ ì •ë³´:\n%s", medical_info_str)
    # LLM í˜¸ì¶œ
    response = llm.invoke(
        prompt_risky.format(
            food_names=food_list_str,
            allergies_name=allergy_list_str,
            disease_name=disease_list_str,
            medical_info=medical_info_str,
            format_instructions=parser.get_format_instructions(),
        )
    )

    try:
        parsed_data = fixing_parser.parse(response.content)

        if not isinstance(parsed_data.foods, list):
            raise ValueError("Invalid JSON format: 'foods' key is not a list")

        return parsed_data.foods

    except Exception as e:
        print(f"LLM JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
        return []
