import { useRef, useState, useEffect } from "react";
import Webcam from "react-webcam";
import axios from "axios";

export default function FaceRecognition() {
  const webcamRef = useRef(null);
  const [image, setImage] = useState(null);
  const [ws, setWs] = useState(null);
  const [response, setResponse] = useState(null);
  const [recognizedUser, setRecognizedUser] = useState(null);

  // ì›¹ì†Œì¼“ ì—°ê²°
  useEffect(() => {
    const socket = new WebSocket("ws://localhost:9000/vision/find_faces/");

    socket.onopen = () => {
      console.log("WebSocket ì—°ê²°ë¨");
    };

    socket.onmessage = (event) => {
      const data = JSON.parse(event.data);
      console.log("ì›¹ì†Œì¼“ ì‘ë‹µ:", data);
      setResponse(data);

      if (data.result && data.result.length === 0) {
        setRecognizedUser(null);
      } else if (data.result && data.result.length > 0) {
        setRecognizedUser(data.result[0].identity);
      }
    };

    socket.onerror = (error) => {
      console.error("WebSocket ì˜¤ë¥˜:", error);
    };

    socket.onclose = () => {
      console.log("WebSocket ì—°ê²° ì¢…ë£Œë¨");
    };

    setWs(socket);

    return () => {
      socket.close();
    };
  }, []);

  const capture = () => {
    const imageSrc = webcamRef.current.getScreenshot();

    const img = new Image();
    img.src = imageSrc;
    img.onload = () => {
      const canvas = document.createElement("canvas");
      const ctx = canvas.getContext("2d");

      canvas.width = img.width;
      canvas.height = img.height;

      ctx.translate(canvas.width, 0);
      ctx.scale(-1, 1);
      ctx.drawImage(img, 0, 0, img.width, img.height);

      const base64Image = canvas.toDataURL("image/jpeg").split(",")[1];
      setImage(base64Image);

      // WebSocketì„ í†µí•´ JSON í˜•íƒœë¡œ ì´ë¯¸ì§€ ì „ì†¡
      if (ws && ws.readyState === WebSocket.OPEN) {
        const payload = {
          image: base64Image,
          level: 2,
          uuid: null, // í•„ìš” ì‹œ uuidë¥¼ ì—¬ê¸°ì— ì¶”ê°€ ê°€ëŠ¥
        };
        ws.send(JSON.stringify(payload));
      }
    };
  };

  return (
    <div className="container mx-auto p-4 max-w-6xl">
      <h1 className="text-2xl font-bold mb-6">ì‹¤ì‹œê°„ ì–¼êµ´ ì¸ì¦ ì‹œìŠ¤í…œ</h1>

      <div className="flex flex-col md:flex-row gap-6">
        <div className="w-full md:w-1/2">
          <div className="mb-6 border rounded-lg overflow-hidden">
            <Webcam ref={webcamRef} screenshotFormat="image/jpeg" mirrored={true} className="w-full" />
          </div>

          <div className="flex gap-4 mb-6">
            <button onClick={capture} className="px-4 py-2 bg-blue-500 text-white rounded-md hover:bg-blue-600">
              ì‚¬ì§„ ì´¬ì˜ ë° ì¸ì¦
            </button>
          </div>

          {recognizedUser && (
            <div className="mb-4 p-4 bg-green-50 border border-green-200 rounded-lg flex items-start">
              <svg
                xmlns="http://www.w3.org/2000/svg"
                className="h-5 w-5 text-green-600 mr-2 mt-0.5"
                viewBox="0 0 24 24"
                fill="none"
                stroke="currentColor"
                strokeWidth="2"
                strokeLinecap="round"
                strokeLinejoin="round"
              >
                <path d="M22 11.08V12a10 10 0 1 1-5.93-9.14"></path>
                <polyline points="22 4 12 14.01 9 11.01"></polyline>
              </svg>
              <div>
                <h4 className="font-medium text-green-800">ì‚¬ìš©ì ì¸ì¦ ì™„ë£Œ</h4>
                <p className="text-green-700">í™˜ì˜í•©ë‹ˆë‹¤, {recognizedUser} ë‹˜!</p>
              </div>
            </div>
          )}

          {response && (
            <div className="mb-4 p-4 bg-gray-50 rounded-lg overflow-auto">
              <h3 className="text-lg font-semibold mb-2">ğŸ“Œ ì–¼êµ´ ì¸ì¦ ì‘ë‹µ:</h3>
              <pre className="text-sm">{JSON.stringify(response, null, 2)}</pre>
            </div>
          )}
        </div>
      </div>
    </div>
  );
}
