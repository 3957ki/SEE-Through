import { getMember, getMembers, getOrCreateMember } from "@/api/members";
import { useCurrentMember } from "@/contexts/CurrentMemberContext";
import { useMembers } from "@/contexts/MembersContext";
import {
  disconnectLocalServer,
  isLocalServerConnected,
  offLocalServerMessage,
  onLocalServerMessage,
  sendToLocalServer,
} from "@/services/websocketService";
import { BoundingBox, FaceDetector, FilesetResolver } from "@mediapipe/tasks-vision";
import { useEffect, useRef, useState } from "react";

const VIDEO_WIDTH = 640;
const VIDEO_HEIGHT = 480;
const SMALL_FACE_CUT = 10000;
const LARGE_FACE_CUT = 25000;
const IOU_CUT = 0.5;

function WebcamView() {
  const videoRef = useRef<HTMLVideoElement>(null);
  const videoCanvasRef = useRef<HTMLCanvasElement>(null);
  const overlayCanvasRef = useRef<HTMLCanvasElement>(null);
  const lastProcessedFrameRef = useRef<ImageData | null>(null);
  const isInitializedRef = useRef(false);

  // ì›¹ìº  ê´€ë ¨ ì—ëŸ¬ ë©”ì‹œì§€
  const [error, setError] = useState<string | null>(null);

  // ë©¤ë²„ ê´€ë ¨ ìƒíƒœ
  const { setMembers } = useMembers();
  const { currentMember, setCurrentMember } = useCurrentMember();

  // Member refs for callbacks
  const currentMemberRef = useRef(currentMember);
  const setMembersRef = useRef(setMembers);
  const setCurrentMemberRef = useRef(setCurrentMember);

  // Frame sending control
  const processingTimeoutRef = useRef<number | null>(null);
  const connectionCheckIntervalRef = useRef<number | null>(null);

  // mediapipe ê´€ë ¨
  const [faceDetector, setFaceDetector] = useState<FaceDetector | null>(null);
  const requestRef = useRef<number>(0);
  const prevBoundingBoxRef = useRef<BoundingBox | null>(null);

  // í˜„ì¬ ì–¼êµ´ ë ˆë²¨
  const [faceLevel, setFaceLevel] = useState<{ level: number; cut: number }>({
    level: 0,
    cut: LARGE_FACE_CUT,
  });
  const faceLevelRef = useRef<{ level: number; cut: number }>({
    level: 0,
    cut: LARGE_FACE_CUT,
  });
  const updateFaceLevel = (newLevel: { level: number; cut: number }) => {
    faceLevelRef.current = newLevel;
    setFaceLevel(newLevel);
  };

  // IOU ê³„ì‚° í•¨ìˆ˜
  const calculateIOU = (boxA: BoundingBox, boxB: BoundingBox): number => {
    const xA = Math.max(boxA.originX, boxB.originX);
    const yA = Math.max(boxA.originY, boxB.originY);
    const xB = Math.min(boxA.originX + boxA.width, boxB.originX + boxB.width);
    const yB = Math.min(boxA.originY + boxA.height, boxB.originY + boxB.height);

    const interArea = Math.max(0, xB - xA) * Math.max(0, yB - yA);
    const boxAArea = boxA.width * boxA.height;
    const boxBArea = boxB.width * boxB.height;

    return interArea / (boxAArea + boxBArea - interArea);
  };

  // ì–¼êµ´ ë ˆë²¨ ìƒíƒœ ë³€ê²½ ì‹œ ë¡œì§
  const handleFaceLevelChange = (newLevel: number) => {
    // ë ˆë²¨ 0: ë¡œê·¸, íƒ€ì´ë¨¸ ì •ë¦¬, 2 ë¡œê·¸ ìƒíƒœ ì´ˆê¸°í™”
    if (newLevel === 0) {
      console.log("[ë ˆë²¨ 0] ì–¼êµ´ ì—†ìŒ");
      setCurrentMemberRef.current(null);
    }

    // ë ˆë²¨ 1: ì£¼ê¸°ì  ìš”ì²­, 2 ë¡œê·¸ ìƒíƒœ ì´ˆê¸°í™”
    else if (newLevel === 1) {
      if (isLocalServerConnected()) {
        console.log("[ë ˆë²¨ 1] ìš”ì²­ ì‹œì‘");
        sendNextFrame(newLevel, null);
      }
    }

    // ë ˆë²¨ 2: ë¡œê·¸ëŠ” ë”± í•œ ë²ˆë§Œ ì¶œë ¥, íƒ€ì´ë¨¸ ì •ë¦¬ (IOU ê°’ì— ë”°ë¥¸ ìš”ì²­ ë¶„ê¸°ë¡œ ìˆ˜ì • ì˜ˆì •)
    else if (newLevel === 2) {
      if (isLocalServerConnected()) {
        console.log("[ë ˆë²¨ 2] ìš”ì²­");
        sendNextFrame(newLevel, null);
      }
    }
  };

  // ì´ë¯¸ì§€ ìš”ì²­ ë³´ë‚´ëŠ” í•¨ìˆ˜
  function sendNextFrame(level: number, uuid: any) {
    if (!isLocalServerConnected()) {
      return;
    }
    console.log(`ì´ë¯¸ì§€ ìš”ì²­ ë³´ë‚´ê¸° level: ${level} uuid: ${uuid}`);

    const video = videoRef.current;
    if (video && video.readyState === video.HAVE_ENOUGH_DATA) {
      const tempCanvas = document.createElement("canvas");
      tempCanvas.width = VIDEO_WIDTH;
      tempCanvas.height = VIDEO_HEIGHT;
      const tempCtx = tempCanvas.getContext("2d");

      if (tempCtx) {
        tempCtx.drawImage(video, 0, 0, VIDEO_WIDTH, VIDEO_HEIGHT);
        lastProcessedFrameRef.current = tempCtx.getImageData(0, 0, VIDEO_WIDTH, VIDEO_HEIGHT);
        const frameData = tempCanvas.toDataURL("image/jpeg", 0.6).split(",")[1];

        processingTimeoutRef.current = window.setTimeout(() => {
          console.warn("[WebSocket] ì‘ë‹µ íƒ€ì„ì•„ì›ƒ");
          sendNextFrame(level, uuid); // timeout í›„ì—ë„ ê³„ì† ì‹œë„
        }, 5000);

        sendToLocalServer({ image: frameData, level: level, uuid: uuid });
      }
    }
  }

  // ì›¹ìº  ì¸ì‹ ì‹œì‘
  useEffect(() => {
    const detectLoop = async () => {
      try {
        if (!faceDetector || !videoRef.current || !overlayCanvasRef.current) {
          requestRef.current = requestAnimationFrame(detectLoop);
          return;
        }

        // ë¯¸ë””ì–´íŒŒì´í”„ ì¸ì‹ ê²°ê³¼
        const detections = faceDetector.detectForVideo(videoRef.current, performance.now());

        let currentBox: BoundingBox | null = null;
        let iouText = "";
        // í˜„ì¬ ìƒíƒœë¥¼ ì§€ì—­ ë³€ìˆ˜ë¡œ ê°€ì ¸ì˜¤ê¸°
        const currentLevel = faceLevelRef.current.level;
        const currentCut = currentLevel === 2 ? SMALL_FACE_CUT : LARGE_FACE_CUT;
        let nextFaceLevel = faceLevel;

        // ì¸ì‹ëœ ì–¼êµ´ì´ ìˆë‹¤ë©´
        if (detections.detections.length > 0) {
          const largestDetection = detections.detections.reduce((largest, current) => {
            const largestBox = largest.boundingBox;
            const currentBox = current.boundingBox;
            if (!largestBox || !currentBox) return largest;
            const largestArea = largestBox.width * largestBox.height;
            const currentArea = currentBox.width * currentBox.height;
            return currentArea > largestArea ? current : largest;
          }, detections.detections[0]);

          currentBox = largestDetection.boundingBox ?? null;

          if (currentBox) {
            const area = currentBox.width * currentBox.height;

            // ë™ê¸°ì ìœ¼ë¡œ cut íŒë‹¨
            if (area >= currentCut) {
              nextFaceLevel = { level: 2, cut: SMALL_FACE_CUT };
            } else {
              nextFaceLevel = { level: 1, cut: LARGE_FACE_CUT };
            }
          }

          const prevBox = prevBoundingBoxRef.current;
          if (currentBox && prevBox) {
            const iou = calculateIOU(currentBox, prevBox);
            iouText = `IOU: ${iou.toFixed(2)}`;

            if (iou < IOU_CUT) {
              console.log("[IOU] ë‚®ì€ IOU ê°ì§€ë¨:", iou.toFixed(2));
              sendNextFrame(nextFaceLevel.level, currentMemberRef.current?.member_id);
            }
          }

          prevBoundingBoxRef.current = currentBox;
        } else {
          nextFaceLevel = { level: 0, cut: LARGE_FACE_CUT };
          prevBoundingBoxRef.current = null;
        }

        if (nextFaceLevel.level !== faceLevelRef.current.level) {
          updateFaceLevel(nextFaceLevel);
          handleFaceLevelChange(nextFaceLevel.level);
        }

        // ìº”ë²„ìŠ¤ì— ê·¸ë¦¬ê¸°
        const ctx = overlayCanvasRef.current.getContext("2d");
        if (ctx) {
          ctx.clearRect(0, 0, VIDEO_WIDTH, VIDEO_HEIGHT);

          // ë°°ê²½ ë¹„ë””ì˜¤ í”„ë ˆì„ ê·¸ë¦¬ê¸°
          if (videoRef.current) {
            ctx.drawImage(videoRef.current, 0, 0, VIDEO_WIDTH, VIDEO_HEIGHT);
          }

          // ì–¼êµ´ ë°•ìŠ¤ ë° IOU í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸°
          if (currentBox) {
            const { originX, originY, width, height } = currentBox;

            let boxColor = "#cccccc"; // ê¸°ë³¸
            if (nextFaceLevel.level === 1)
              boxColor = "#ff0000"; // ë¹¨ê°•
            else if (nextFaceLevel.level === 2) boxColor = "#00ff00"; // ì´ˆë¡

            ctx.strokeStyle = boxColor;

            ctx.beginPath();
            ctx.lineWidth = 3;
            ctx.strokeRect(originX, originY, width, height);

            ctx.fillStyle = "rgba(0, 255, 0, 0.7)";
            ctx.fillRect(originX, originY - 40, 120, 40);
            ctx.fillStyle = "#000000";
            ctx.font = "14px Arial";
            ctx.fillText("ì–¼êµ´ ê°ì§€ë¨", originX + 5, originY - 25);
            if (iouText) {
              ctx.fillText(iouText, originX + 5, originY - 10);
            }
          }
        }
      } catch (e) {
        console.error("[MediaPipe] Face detection error:", e);
      }

      requestRef.current = requestAnimationFrame(detectLoop);
    };

    requestRef.current = requestAnimationFrame(detectLoop);

    return () => {
      if (requestRef.current) {
        cancelAnimationFrame(requestRef.current);
      }
    };
  }, [faceDetector]);

  // Update refs when values change
  useEffect(() => {
    currentMemberRef.current = currentMember;
    setMembersRef.current = setMembers;
    setCurrentMemberRef.current = setCurrentMember;
  }, [currentMember, setMembers, setCurrentMember]);

  const init = async () => {
    if (isInitializedRef.current) return;

    try {
      // Start webcam
      const stream = await navigator.mediaDevices.getUserMedia({
        video: {
          width: VIDEO_WIDTH,
          height: VIDEO_HEIGHT,
        },
      });

      if (videoRef.current) {
        videoRef.current.srcObject = stream;
        // ë¹„ë””ì˜¤ê°€ ë©”íƒ€ë°ì´í„°ë¥¼ ë¡œë“œí–ˆì„ ë•Œ ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ
        videoRef.current.onloadedmetadata = () => {
          if (videoRef.current) {
            videoRef.current.play().catch((err) => {
              console.error("ë¹„ë””ì˜¤ ì¬ìƒ ì‹¤íŒ¨:", err);
              setError("ë¹„ë””ì˜¤ ì¬ìƒ ì‹¤íŒ¨: " + err.message);
            });
          }
        };
      }

      // Setup canvases
      const videoCanvas = videoCanvasRef.current;
      const overlayCanvas = overlayCanvasRef.current;
      if (videoCanvas && overlayCanvas) {
        const ctx = videoCanvas.getContext("2d");
        const overlayCtx = overlayCanvas.getContext("2d");
        if (ctx && overlayCtx) {
          // Set canvas dimensions to match video
          videoCanvas.width = VIDEO_WIDTH;
          videoCanvas.height = VIDEO_HEIGHT;
          overlayCanvas.width = VIDEO_WIDTH;
          overlayCanvas.height = VIDEO_HEIGHT;

          // Configure contexts for crisp rendering
          ctx.imageSmoothingEnabled = false;
          overlayCtx.imageSmoothingEnabled = false;
          console.log("[Canvas] Canvas dimensions set:", {
            width: videoCanvas.width,
            height: videoCanvas.height,
          });
        }
      }

      isInitializedRef.current = true;
    } catch (err) {
      setError("ì›¹ìº ì„ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: " + (err as Error).message);
      console.error("Failed to start webcam:", err);
    }
  };

  const cleanup = () => {
    if (videoRef.current?.srcObject) {
      const stream = videoRef.current.srcObject as MediaStream;
      stream.getTracks().forEach((track) => track.stop());
    }

    if (connectionCheckIntervalRef.current) {
      window.clearInterval(connectionCheckIntervalRef.current);
    }
    if (processingTimeoutRef.current) {
      window.clearTimeout(processingTimeoutRef.current);
    }
    disconnectLocalServer();
  };

  useEffect(() => {
    const runInitAndLoad = async () => {
      try {
        await init(); // ë¨¼ì € ì›¹ìº  ì‹œì‘

        // ìµœì‹  WASM ê²½ë¡œë¡œ ìˆ˜ì •
        const filesetResolver = await FilesetResolver.forVisionTasks(
          "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm"
        );

        const detector = await FaceDetector.createFromOptions(filesetResolver, {
          baseOptions: {
            modelAssetPath:
              "https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite",
            delegate: "GPU",
          },
          runningMode: "VIDEO",
        });

        setFaceDetector(detector);

        console.log("[MediaPipe] Face detector loaded successfully");
      } catch (err) {
        console.error("[MediaPipe] Setup error:", err);
        setError("MediaPipe ì„¤ì • ì˜¤ë¥˜: " + (err as Error).message);
      }
    };

    runInitAndLoad();
    return cleanup;
  }, []);

  // ì–¼êµ´ ë ˆë²¨ì— ë”°ë¥¸ ê¸°ëŠ¥
  useEffect(() => {
    let shouldContinue = true;

    // ì›¹ì†Œì¼“ ë©”ì‹œì§€ í•¸ë“¤ëŸ¬
    async function handleFaceRecognition(result: any) {
      if (processingTimeoutRef.current) {
        clearTimeout(processingTimeoutRef.current);
        processingTimeoutRef.current = null;
      }

      console.log("[WebSocket] ì‘ë‹µ ìˆ˜ì‹ :", result);

      const isNew = result?.is_new;
      const detected = result?.result?.[0];
      const memberId = detected?.identity;

      if (!memberId) {
        // ì¸ì‹ ê²°ê³¼ ì—†ìŒ â†’ ë¬´ì¡°ê±´ null ì²˜ë¦¬
        setCurrentMemberRef.current(null);
      }
      // ìƒˆë¡œìš´ ì•„ì´ë””ë¼ë©´
      else if (isNew) {
        try {
          // ì‹ ê·œ ë“±ë¡í•˜ê¸°
          const newMember = await getOrCreateMember({
            member_id: memberId,
            age: 0,
            image_path: "null",
          });
          const members = await getMembers();
          setMembersRef.current(members);
          setCurrentMemberRef.current(newMember);
        } catch (err) {
          console.error("[WebSocket] ë©¤ë²„ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨:", err);
        }
      }

      // ìƒˆë¡œìš´ ì•„ì´ë””ê°€ ì•„ë‹Œë° í˜„ì¬ ë©¤ë²„ ì•„ì´ë””ì™€ ë‹¤ë¥¼ ë•Œ
      else if (memberId !== currentMemberRef.current?.member_id) {
        try {
          // ì¸ì‹ëœ ë©¤ë²„ê°€ ìˆì„ë•Œ ê°€ì ¸ì˜¤ê¸°ë§Œ í•¨
          const newMember = await getMember(memberId);
          setCurrentMemberRef.current(newMember);
        } catch (err) {
          console.error("[WebSocket] ë©¤ë²„ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨:", err);
        }
      }

      // 1ë‹¨ê³„ì¸ë° ì§ì „ ë©¤ë²„ idê°€ ì¡´ì¬í•˜ê³  í˜„ì¬ ì¸ì‹ ê²°ê³¼ê°€ ì—†ì„ ë•Œ íšŒì›ì„ nullë¡œ ê°±ì‹ 
      // else if (
      //   faceLevelRef.current.level === 1 &&
      //   currentMemberRef.current?.member_id &&
      //   !memberId
      // ) {
      //   setCurrentMemberRef.current(null);
      // }

      // ë ˆë²¨ 1ì´ë¼ë©´ ë‹¤ìŒ í”„ë ˆì„ 0.1ì´ˆ í›„ ì „ì†¡
      if (shouldContinue && faceLevelRef.current.level === 1) {
        setTimeout(() => {
          if (shouldContinue && faceLevelRef.current.level === 1) {
            sendNextFrame(1, null);
          }
        }, 100);
      }
    }

    onLocalServerMessage(handleFaceRecognition);

    return () => {
      shouldContinue = false;
      offLocalServerMessage(handleFaceRecognition);
      if (processingTimeoutRef.current) {
        clearTimeout(processingTimeoutRef.current);
      }
    };
  }, []);

  // useEffect(() => {
  //   async function handleFaceRecognition(result: FaceDetectionResult) {
  //     // Clear the processing timeout since we got a response
  //     if (processingTimeoutRef.current) {
  //       window.clearTimeout(processingTimeoutRef.current);
  //       processingTimeoutRef.current = null;
  //     }

  //     console.log("[WebSocket] Received face recognition response:", new Date().toISOString());
  //     console.log("[Face Detection] Result:", result);

  //     // Draw the frame that was processed
  //     if (lastProcessedFrameRef.current && videoCanvasRef.current) {
  //       const ctx = videoCanvasRef.current.getContext("2d");
  //       if (ctx) {
  //         // Clear and put the new frame data directly
  //         ctx.clearRect(0, 0, VIDEO_WIDTH, VIDEO_HEIGHT);
  //         ctx.putImageData(lastProcessedFrameRef.current, 0, 0);

  //         // Draw face box if face detected
  //         if (result.result && result.result.length > 0) {
  //           const { identity: memberId } = result.result[0];
  //           console.log("[Face Detection] Detected member:", memberId);

  //           // í˜„ì¬ ë©¤ë²„ë‘ ë‹¤ë¥¸ ê²½ìš°ì—ë§Œ ì—…ë°ì´íŠ¸í•˜ê¸°
  //           if (currentMemberRef.current?.member_id !== memberId) {
  //             (async () => {
  //               try {
  //                 // 1. Create new member
  //                 const newMember = await createAndGetMember({
  //                   member_id: memberId,
  //                   age: 0,
  //                   image_path: "null",
  //                 });

  //                 // 2. Update members
  //                 const members = await getMembers();
  //                 setMembers(members);

  //                 // 3. Set current member
  //                 setCurrentMember(newMember);
  //               } catch (error) {
  //                 console.error("Failed to create or update member:", error);
  //               }
  //             })();
  //           }

  //           // ë°•ìŠ¤ ê·¸ë¦¬ê¸°
  //           const face = result.result[0];
  //           console.log("[Face Box] Drawing box with coordinates:", {
  //             x: face.source_x,
  //             y: face.source_y,
  //             w: face.source_w,
  //             h: face.source_h,
  //           });

  //           if (
  //             typeof face.source_x === "number" &&
  //             typeof face.source_y === "number" &&
  //             typeof face.source_w === "number" &&
  //             typeof face.source_h === "number"
  //           ) {
  //             // Draw face box with yellow color
  //             ctx.beginPath();
  //             ctx.strokeStyle = "#ffff00"; // Yellow box
  //             ctx.lineWidth = 3;
  //             ctx.strokeRect(face.source_x, face.source_y, face.source_w, face.source_h);

  //             console.log("[Face Box] Box drawn successfully");
  //           }
  //         }

  //         // Clear the stored frame after drawing
  //         lastProcessedFrameRef.current = null;

  //         // Mark processing as complete and send next frame
  //         isProcessingRef.current = false;
  //         sendNextFrame();
  //       }
  //     } else {
  //       // If no frame was stored, just send next frame
  //       isProcessingRef.current = false;
  //       sendNextFrame();
  //     }
  //   }

  //   function sendNextFrame() {
  //     // Don't send if already processing
  //     if (isProcessingRef.current) {
  //       console.log("[Frame] Skipping send - already processing");
  //       return;
  //     }

  //     // Don't send if not connected
  //     if (!isLocalServerConnected()) {
  //       console.log("[Frame] Skipping send - not connected");
  //       return;
  //     }

  //     const video = videoRef.current;
  //     if (video && video.readyState === video.HAVE_ENOUGH_DATA) {
  //       // Create a temporary canvas for frame extraction
  //       const tempCanvas = document.createElement("canvas");
  //       tempCanvas.width = VIDEO_WIDTH;
  //       tempCanvas.height = VIDEO_HEIGHT;
  //       const tempCtx = tempCanvas.getContext("2d");

  //       if (tempCtx) {
  //         // Draw current video frame to temporary canvas
  //         tempCtx.drawImage(video, 0, 0, VIDEO_WIDTH, VIDEO_HEIGHT);

  //         // Store the frame data as ImageData
  //         lastProcessedFrameRef.current = tempCtx.getImageData(0, 0, VIDEO_WIDTH, VIDEO_HEIGHT);

  //         // Convert ImageData to base64 for sending
  //         const frameData = tempCanvas.toDataURL("image/jpeg", 0.6).split(",")[1];

  //         // Mark as processing and send frame
  //         isProcessingRef.current = true;

  //         // Set a timeout to handle cases where we don't get a response
  //         processingTimeoutRef.current = window.setTimeout(() => {
  //           console.log(
  //             "[WebSocket] Frame processing timeout, resetting state...",
  //             new Date().toISOString()
  //           );
  //           isProcessingRef.current = false;
  //           sendNextFrame();
  //         }, 5000); // 5 second timeout

  //         console.log("[WebSocket] Sending frame to server:", new Date().toISOString());
  //         sendToLocalServer({ image: frameData, level: 1, uuid: null });
  //       }
  //     } else {
  //       console.log("[Frame] Skipping send - video not ready");
  //     }
  //   }

  //   // Function to check connection and start sending frames
  //   const checkConnectionAndStart = () => {
  //     if (isLocalServerConnected() && !isProcessingRef.current) {
  //       sendNextFrame();
  //     }
  //   };

  //   // Register WebSocket message handler
  //   onLocalServerMessage(handleFaceRecognition);

  //   // Start checking for connection and periodically check
  //   checkConnectionAndStart();
  //   connectionCheckIntervalRef.current = window.setInterval(checkConnectionAndStart, 500);

  //   // Cleanup
  //   return () => {
  //     // offLocalServerMessage(handleFaceRecognition);
  //     if (connectionCheckIntervalRef.current) {
  //       window.clearInterval(connectionCheckIntervalRef.current);
  //     }
  //     if (processingTimeoutRef.current) {
  //       window.clearTimeout(processingTimeoutRef.current);
  //     }
  //     disconnectLocalServer();
  //   };
  // }, []); // Remove dependencies that cause re-renders

  if (error) {
    return (
      <div className="bg-black rounded-md w-full h-full flex items-center justify-center">
        <p className="text-red-400 text-center text-sm">{error}</p>
      </div>
    );
  }

  return (
    <div className="bg-black rounded-md w-full h-full flex items-center justify-center relative">
      {/* ìƒíƒœ ì •ë³´ í‘œì‹œ */}
      {/* <div className="absolute top-2 left-2 z-10 bg-white bg-opacity-80 text-black p-2 rounded text-sm shadow">
        <p>ğŸ§  ì–¼êµ´ ë ˆë²¨: {faceLevel.level}</p>
        <p>ğŸ™â€â™‚ï¸ ë©¤ë²„ ID: {currentMember?.member_id ?? "ì—†ìŒ"}</p>
      </div> */}
      <video
        ref={videoRef}
        autoPlay
        playsInline
        muted
        className="absolute inset-0 w-full h-full object-cover"
        style={{ opacity: 0 }}
      />
      <canvas
        ref={videoCanvasRef}
        width={VIDEO_WIDTH}
        height={VIDEO_HEIGHT}
        className="w-full h-full object-cover"
        style={{ position: "absolute", top: 0, left: 0 }}
      />
      <canvas
        ref={overlayCanvasRef}
        width={VIDEO_WIDTH}
        height={VIDEO_HEIGHT}
        className="w-full h-full object-cover"
        style={{ position: "absolute", top: 0, left: 0 }}
      />
    </div>
  );
}

export default WebcamView;
